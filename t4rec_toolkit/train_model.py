
# === ENTRA√éNEMENT T4REC XLNET AVEC M√âTRIQUES ===

print("üèãÔ∏è ENTRA√éNEMENT T4REC XLNET")
print("=" * 50)

import torch
import torch.nn as nn
import transformers4rec.torch as tr
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from torch.utils.data import DataLoader, TensorDataset
import time

# V√©rifier que le mod√®le existe
if "model" not in globals():
    print("‚ùå Mod√®le non trouv√©. Ex√©cutez d'abord le script de cr√©ation du mod√®le.")
    raise RuntimeError("Mod√®le requis")

if "inputs" not in globals():
    print(
        "‚ùå Donn√©es d'entr√©e non trouv√©es. Ex√©cutez d'abord le script de cr√©ation du mod√®le."
    )
    raise RuntimeError("Donn√©es requises")

print("‚úÖ Mod√®le et donn√©es trouv√©s")

# === CONFIGURATION D'ENTRA√éNEMENT ===
TRAINING_CONFIG = {
    "batch_size": 8,  # Petit batch pour la stabilit√©
    "learning_rate": 1e-4,  # Learning rate conservateur
    "num_epochs": 3,  # Peu d'√©poques pour le test
    "weight_decay": 1e-5,  # R√©gularisation l√©g√®re
    "warmup_steps": 10,  # Warm-up minimal
    "eval_every": 50,  # √âvaluation fr√©quente
    "patience": 5,  # Early stopping
    "max_grad_norm": 1.0,  # Gradient clipping
}

print(f"üìã Configuration: {TRAINING_CONFIG}")

# === PR√âPARATION DES DONN√âES D'ENTRA√éNEMENT ===
print("\nüìä Pr√©paration des donn√©es d'entra√Ænement...")

# R√©cup√©rer les donn√©es du mod√®le cr√©√© pr√©c√©demment
item_sequences = inputs["item_id"]  # Shape: [n_sessions, seq_len]
user_sequences = inputs["user_id"]  # Shape: [n_sessions, seq_len]

n_sessions, seq_len = item_sequences.shape
print(f"‚úÖ Donn√©es: {n_sessions} sessions de {seq_len} items")

# Cr√©er les targets (next item prediction)
# Target = le prochain item dans la s√©quence
targets = torch.zeros_like(item_sequences)
targets[:, :-1] = item_sequences[:, 1:]  # D√©caler d'une position
targets[:, -1] = item_sequences[:, 0]  # Dernier -> premier (cyclique)

print(f"‚úÖ Targets cr√©√©s: {targets.shape}")

# Split train/validation
n_train = int(0.8 * n_sessions)
train_inputs = {
    "item_id": item_sequences[:n_train],
    "user_id": user_sequences[:n_train],
}
train_targets = targets[:n_train]

val_inputs = {"item_id": item_sequences[n_train:], "user_id": user_sequences[n_train:]}
val_targets = targets[n_train:]

print(
    f"‚úÖ Split: {len(train_inputs['item_id'])} train, {len(val_inputs['item_id'])} val"
)


# === FONCTION D'ENTRA√éNEMENT ===
def create_batch_iterator(inputs_dict, targets, batch_size, shuffle=True):
    """Cr√©er un it√©rateur de batch pour T4Rec."""
    n_samples = len(targets)
    indices = torch.randperm(n_samples) if shuffle else torch.arange(n_samples)

    for i in range(0, n_samples, batch_size):
        batch_indices = indices[i : i + batch_size]
        batch_inputs = {k: v[batch_indices] for k, v in inputs_dict.items()}
        batch_targets = targets[batch_indices]
        yield batch_inputs, batch_targets


# === OPTIMIZER ET SCHEDULER ===
print("\n‚öôÔ∏è Configuration optimizer...")

optimizer = torch.optim.AdamW(
    model.parameters(),
    lr=TRAINING_CONFIG["learning_rate"],
    weight_decay=TRAINING_CONFIG["weight_decay"],
)

# Scheduler avec warmup
from torch.optim.lr_scheduler import LambdaLR


def lr_lambda(current_step):
    if current_step < TRAINING_CONFIG["warmup_steps"]:
        return float(current_step) / float(max(1, TRAINING_CONFIG["warmup_steps"]))
    return 1.0


scheduler = LambdaLR(optimizer, lr_lambda)

print("‚úÖ Optimizer et scheduler configur√©s")


# === M√âTRIQUES PERSONNALIS√âES ===
class SimpleMetrics:
    def __init__(self):
        self.reset()

    def reset(self):
        self.total_loss = 0.0
        self.total_accuracy = 0.0
        self.total_samples = 0
        self.batch_count = 0

    def update(self, loss, predictions, targets):
        batch_size = len(targets)
        self.total_loss += loss * batch_size

        # Calculer accuracy (top-1)
        if len(predictions.shape) > 2:
            # Si predictions a 3 dimensions [batch, seq, vocab]
            pred_flat = predictions.view(-1, predictions.size(-1))
            target_flat = targets.view(-1)
            pred_classes = torch.argmax(pred_flat, dim=-1)
            correct = (pred_classes == target_flat).float().sum().item()
            accuracy = correct / len(target_flat)
        else:
            # Si predictions a 2 dimensions
            pred_classes = torch.argmax(predictions, dim=-1)
            correct = (pred_classes == targets).float().sum().item()
            accuracy = correct / batch_size

        self.total_accuracy += accuracy * batch_size
        self.total_samples += batch_size
        self.batch_count += 1

    def compute(self):
        if self.total_samples == 0:
            return {"loss": 0.0, "accuracy": 0.0}

        return {
            "loss": self.total_loss / self.total_samples,
            "accuracy": self.total_accuracy / self.total_samples,
        }


# === FONCTION D'√âVALUATION ===
def evaluate_model(model, eval_inputs, eval_targets, batch_size):
    """√âvaluer le mod√®le sur les donn√©es de validation."""
    model.eval()
    metrics = SimpleMetrics()

    with torch.no_grad():
        for batch_inputs, batch_targets in create_batch_iterator(
            eval_inputs, eval_targets, batch_size, shuffle=False
        ):
            try:
                outputs = model(batch_inputs)

                # Calculer la loss
                if hasattr(outputs, "loss"):
                    loss = outputs.loss.item()
                    predictions = (
                        outputs.prediction_scores
                        if hasattr(outputs, "prediction_scores")
                        else outputs
                    )
                else:
                    # Fallback si pas de loss dans les outputs
                    loss = 0.0
                    predictions = outputs

                metrics.update(loss, predictions, batch_targets)

            except Exception as e:
                print(f"‚ö†Ô∏è Erreur √©valuation batch: {e}")
                continue

    return metrics.compute()


# === BOUCLE D'ENTRA√éNEMENT ===
print(f"\nüèãÔ∏è D√©but de l'entra√Ænement ({TRAINING_CONFIG['num_epochs']} √©poques)...")

# Historique des m√©triques
history = {"train_loss": [], "train_acc": [], "val_loss": [], "val_acc": [], "lr": []}

best_val_loss = float("inf")
patience_counter = 0
global_step = 0

model.train()

for epoch in range(TRAINING_CONFIG["num_epochs"]):
    print(f"\nüìà √âpoque {epoch + 1}/{TRAINING_CONFIG['num_epochs']}")

    epoch_metrics = SimpleMetrics()
    epoch_start_time = time.time()

    # Entra√Ænement
    for batch_idx, (batch_inputs, batch_targets) in enumerate(
        create_batch_iterator(
            train_inputs, train_targets, TRAINING_CONFIG["batch_size"]
        )
    ):
        try:
            optimizer.zero_grad()

            # Forward pass
            outputs = model(batch_inputs)

            # Calculer la loss
            if hasattr(outputs, "loss"):
                loss = outputs.loss
                predictions = (
                    outputs.prediction_scores
                    if hasattr(outputs, "prediction_scores")
                    else outputs
                )
            else:
                # Fallback: calculer une loss simple
                if len(outputs.shape) == 3:
                    # [batch, seq, vocab] -> [batch*seq, vocab]
                    output_flat = outputs.view(-1, outputs.size(-1))
                    target_flat = batch_targets.view(-1)
                    loss = nn.CrossEntropyLoss()(output_flat, target_flat)
                else:
                    loss = nn.CrossEntropyLoss()(outputs, batch_targets.view(-1))
                predictions = outputs

            # Backward pass
            loss.backward()

            # Gradient clipping
            torch.nn.utils.clip_grad_norm_(
                model.parameters(), TRAINING_CONFIG["max_grad_norm"]
            )

            optimizer.step()
            scheduler.step()

            # M√©triques
            epoch_metrics.update(loss.item(), predictions, batch_targets)
            global_step += 1

            # Log p√©riodique
            if batch_idx % 20 == 0:
                current_lr = scheduler.get_last_lr()[0]
                print(
                    f"  Batch {batch_idx}: loss={loss.item():.4f}, lr={current_lr:.6f}"
                )

            # √âvaluation p√©riodique
            if global_step % TRAINING_CONFIG["eval_every"] == 0:
                print(f"\nüîç √âvaluation step {global_step}...")
                val_metrics = evaluate_model(
                    model, val_inputs, val_targets, TRAINING_CONFIG["batch_size"]
                )
                print(
                    f"  Val: loss={val_metrics['loss']:.4f}, acc={val_metrics['accuracy']:.4f}"
                )

                # Early stopping
                if val_metrics["loss"] < best_val_loss:
                    best_val_loss = val_metrics["loss"]
                    patience_counter = 0
                    print("  ‚úÖ Nouveau meilleur mod√®le sauvegard√©")
                else:
                    patience_counter += 1

                model.train()  # Retour en mode train

        except Exception as e:
            print(f"‚ö†Ô∏è Erreur batch {batch_idx}: {e}")
            continue

    # M√©triques fin d'√©poque
    train_metrics = epoch_metrics.compute()
    val_metrics = evaluate_model(
        model, val_inputs, val_targets, TRAINING_CONFIG["batch_size"]
    )

    epoch_time = time.time() - epoch_start_time
    current_lr = scheduler.get_last_lr()[0]

    # Sauvegarde historique
    history["train_loss"].append(train_metrics["loss"])
    history["train_acc"].append(train_metrics["accuracy"])
    history["val_loss"].append(val_metrics["loss"])
    history["val_acc"].append(val_metrics["accuracy"])
    history["lr"].append(current_lr)

    print(f"\nüìä √âpoque {epoch + 1} termin√©e ({epoch_time:.1f}s)")
    print(
        f"  Train: loss={train_metrics['loss']:.4f}, acc={train_metrics['accuracy']:.4f}"
    )
    print(f"  Val:   loss={val_metrics['loss']:.4f}, acc={val_metrics['accuracy']:.4f}")
    print(f"  LR: {current_lr:.6f}")

    # Early stopping check
    if patience_counter >= TRAINING_CONFIG["patience"]:
        print(f"\n‚èπÔ∏è Early stopping apr√®s {patience_counter} √©poques sans am√©lioration")
        break

print(f"\nüéâ ENTRA√éNEMENT TERMIN√â!")
print(f"üìä Meilleure val loss: {best_val_loss:.4f}")

# === R√âSUM√â FINAL ===
print(f"\nüìà R√âSUM√â FINAL:")
print(f"  üèãÔ∏è √âpoques: {len(history['train_loss'])}")
print(f"  üìâ Train loss finale: {history['train_loss'][-1]:.4f}")
print(f"  üìâ Val loss finale: {history['val_loss'][-1]:.4f}")
print(f"  üéØ Train accuracy: {history['train_acc'][-1]:.2%}")
print(f"  üéØ Val accuracy: {history['val_acc'][-1]:.2%}")

# === GRAPHIQUES SIMPLES (optionnel) ===
try:
    import matplotlib.pyplot as plt

    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 8))

    # Loss
    ax1.plot(history["train_loss"], label="Train")
    ax1.plot(history["val_loss"], label="Validation")
    ax1.set_title("Loss")
    ax1.legend()

    # Accuracy
    ax2.plot(history["train_acc"], label="Train")
    ax2.plot(history["val_acc"], label="Validation")
    ax2.set_title("Accuracy")
    ax2.legend()

    # Learning Rate
    ax3.plot(history["lr"])
    ax3.set_title("Learning Rate")

    # Val Loss zoom
    ax4.plot(history["val_loss"])
    ax4.set_title("Validation Loss")

    plt.tight_layout()
    plt.show()

    print("üìä Graphiques affich√©s")

except ImportError:
    print("üìä Matplotlib non disponible pour les graphiques")

print("\n" + "=" * 50)
print("Entra√Ænement termin√© avec succ√®s!")
