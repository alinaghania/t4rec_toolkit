# === T4REC XLNET INT√âGR√â AVEC VOS DONN√âES ===

print("üöÄ T4REC XLNET - UTILISANT VOS DONN√âES TRANSFORM√âES")
print("=" * 65)

import torch
import transformers4rec.torch as tr
import numpy as np
import pandas as pd
from sklearn.preprocessing import LabelEncoder

try:
    # V√©rifier que les variables n√©cessaires existent
    if "tabular_data" not in globals():
        print(
            "‚ùå Variable 'tabular_data' non trouv√©e. Ex√©cutez d'abord le script de pr√©paration des donn√©es."
        )
        raise NameError("tabular_data non d√©finie")

    if "df" not in globals():
        print(
            "‚ùå Variable 'df' non trouv√©e. Ex√©cutez d'abord le script de chargement des donn√©es."
        )
        raise NameError("df non d√©finie")

    print(
        f"‚úÖ Donn√©es disponibles: {len(tabular_data)} features, {len(df)} √©chantillons"
    )

    # Configuration T4Rec pour version 23.04.00
    CONFIG = {
        "d_model": 128,
        "n_head": 4,
        "n_layer": 2,
        "max_sequence_length": 15,
        "mem_len": 30,
        "dropout": 0.1,
        "hidden_size": 128,
        "vocab_size": 100,
    }

    # 1. Cr√©er le sch√©ma T4Rec SEULEMENT avec features cat√©gorielles
    print("\nüìã Sch√©ma T4Rec avec features cat√©gorielles...")

    from merlin.schema import Schema, ColumnSchema, Tags

    # Utiliser vos features existantes comme base
    n_samples = len(next(iter(tabular_data.values())))

    # Cr√©er des features cat√©gorielles bas√©es sur vos donn√©es
    print(f"√âchantillons disponibles: {n_samples}")

    # Item IDs : cycle sur une plage
    item_ids = np.arange(n_samples) % 99 + 1  # IDs de 1 √† 99

    # User categories : bas√© sur vos features dummy existantes
    categorical_features = [name for name in tabular_data.keys() if "dummy" in name]
    print(f"Features cat√©gorielles trouv√©es: {categorical_features[:3]}...")

    if categorical_features:
        # Utiliser la premi√®re feature dummy comme base
        base_feature = tabular_data[categorical_features[0]]
        if hasattr(base_feature, "flatten"):
            base_values = base_feature.flatten()
        else:
            base_values = np.array(base_feature)
        user_categories = (base_values % 19) + 1  # 1 √† 19
    else:
        user_categories = np.random.randint(1, 20, n_samples)

    print(f"‚úÖ item_id: {len(np.unique(item_ids))} uniques")
    print(f"‚úÖ user_category: {len(np.unique(user_categories))} uniques")

    # Sch√©ma Merlin simplifi√©
    columns = [
        ColumnSchema(
            "item_id",
            tags=[Tags.CATEGORICAL, Tags.ITEM, Tags.ID],
            dtype=np.int32,
            properties={"domain": {"min": 1, "max": 100}},
        ),
        ColumnSchema(
            "user_category",
            tags=[Tags.CATEGORICAL, Tags.USER],
            dtype=np.int32,
            properties={"domain": {"min": 1, "max": 20}},
        ),
    ]

    schema = Schema(columns)
    print(f"‚úÖ Sch√©ma cr√©√© avec {len(columns)} colonnes")

    # 2. Pr√©parer les donn√©es pour T4Rec
    print("\nüìä Pr√©paration des donn√©es T4Rec...")

    t4rec_data = {
        "item_id": item_ids.astype(np.int64),
        "user_category": user_categories.astype(np.int64),
    }

    # 3. Cr√©er le module d'entr√©e
    print("\nüèóÔ∏è Module d'entr√©e...")

    input_module = tr.TabularSequenceFeatures.from_schema(
        schema=schema,
        max_sequence_length=CONFIG["max_sequence_length"],
        aggregation="concat",
        masking=None,
        automatic_build=False,
    )

    print(f"‚úÖ Module cr√©√©: {type(input_module).__name__}")

    # 4. Configuration du masking
    print("\nüé≠ Configuration du masking...")

    try:
        from transformers4rec.torch.masking import MaskSequence

        masking_module = MaskSequence(
            schema=schema.select_by_tag(Tags.ITEM),
            hidden_size=CONFIG["hidden_size"],
            max_sequence_length=CONFIG["max_sequence_length"],
            masking_prob=0.2,
            padding_idx=0,
        )

        input_module.masking = masking_module
        print(f"‚úÖ Masking assign√©")

    except Exception as masking_error:
        print(f"‚ö†Ô∏è Erreur masking: {masking_error}")
        input_module.masking = None
        print("‚ö†Ô∏è Continuons sans masking")

    # 5. Configuration XLNet (CORRIG√âE)
    print("\n‚öôÔ∏è Configuration XLNet...")

    xlnet_config = tr.XLNetConfig.build(
        d_model=CONFIG["d_model"],
        n_head=CONFIG["n_head"],
        n_layer=CONFIG["n_layer"],
        total_seq_length=CONFIG["max_sequence_length"],
        mem_len=CONFIG["mem_len"],
        dropout=CONFIG["dropout"],
        attn_type="bi",
        initializer_range=0.02,
        hidden_act="gelu",
        layer_norm_eps=1e-12,
        pad_token=0,
        # PAS de vocab_size ici pour √©viter le conflit
    )

    print(
        f"‚úÖ XLNet configur√©: {CONFIG['d_model']}d, {CONFIG['n_head']}h, {CONFIG['n_layer']}l"
    )

    # 6. Construire le mod√®le
    print("\nüöÄ Construction du mod√®le...")

    # D'abord, construire le module d'entr√©e avec un batch dummy
    print("üîß Construction du module d'entr√©e...")
    dummy_batch = {}
    for key, data in t4rec_data.items():
        tensor = torch.tensor(data[:4], dtype=torch.long)  # Petit batch
        seq_tensor = tensor.unsqueeze(1).expand(-1, CONFIG["max_sequence_length"])
        dummy_batch[key] = seq_tensor

    # Construire le module d'entr√©e
    input_output = input_module(dummy_batch)
    print(f"‚úÖ Module d'entr√©e construit, output shape: {input_output.shape}")

    # Maintenant construire le corps avec les bonnes dimensions
    body = tr.SequentialBlock(
        input_module,
        tr.TransformerBlock(xlnet_config, masking=input_module.masking),
        tr.MLPBlock([CONFIG["d_model"]]),  # Projection vers la dimension du mod√®le
    )

    from transformers4rec.torch.ranking_metric import NDCGAt, RecallAt

    head = tr.Head(
        body,
        tr.NextItemPredictionTask(
            weight_tying=True,
            metrics=[
                NDCGAt(top_ks=[5, 10], labels_onehot=True),
                RecallAt(top_ks=[5, 10], labels_onehot=True),
            ],
        ),
        inputs=input_module,
    )

    model = tr.Model(head)

    print(f"‚úÖ Mod√®le cr√©√©!")
    print(f"üìà Param√®tres: {sum(p.numel() for p in model.parameters()):,}")

    # 7. Test du mod√®le
    print("\nüß™ Test du mod√®le...")

    batch_size = 16
    test_batch = {}

    for key, data in t4rec_data.items():
        tensor = torch.tensor(data[:batch_size], dtype=torch.long)
        # Cr√©er des s√©quences
        seq_tensor = tensor.unsqueeze(1).expand(-1, CONFIG["max_sequence_length"])
        test_batch[key] = seq_tensor

    print(f"Batch de test: {[(k, v.shape) for k, v in test_batch.items()]}")

    model.eval()
    with torch.no_grad():
        try:
            output = model(test_batch)
            print(f"‚úÖ Test r√©ussi! Output shape: {output.shape}")
            test_success = True
        except Exception as test_error:
            print(f"‚ùå Test √©chou√©: {test_error}")
            print(f"Type d'erreur: {type(test_error).__name__}")
            import traceback

            traceback.print_exc()
            test_success = False

    if test_success:
        print("\nüéØ Pr√©paration pour l'entra√Ænement...")

        # Pr√©parer les s√©quences compl√®tes
        full_sequences = {}

        for key, data in t4rec_data.items():
            tensor = torch.tensor(data, dtype=torch.long)
            sequences = []

            for i in range(len(tensor)):
                # Cr√©er une s√©quence r√©aliste
                seq = torch.full(
                    (CONFIG["max_sequence_length"],), tensor[i], dtype=tensor.dtype
                )

                # Ajouter de la variabilit√©
                if i > 0:
                    start_idx = max(0, i - CONFIG["max_sequence_length"] + 1)
                    prev_values = tensor[start_idx:i]
                    if len(prev_values) > 0:
                        seq[-len(prev_values) :] = prev_values
                    seq[-1] = tensor[i]

                sequences.append(seq)

            full_sequences[key] = torch.stack(sequences)

        print(f"S√©quences cr√©√©es: {[(k, v.shape) for k, v in full_sequences.items()]}")

        # Pr√©parer les labels
        target_col = "souscription_produit_1m"
        if target_col in df.columns:
            y = df[target_col].values
            label_encoder = LabelEncoder()
            y_encoded = label_encoder.fit_transform(y)
            y_tensor = torch.tensor(y_encoded, dtype=torch.long)

            print(f"‚úÖ Labels pr√©par√©s: {len(np.unique(y_encoded))} classes")

            # Split des donn√©es
            n_total = len(y_tensor)
            n_train = int(0.8 * n_total)

            train_sequences = {k: v[:n_train] for k, v in full_sequences.items()}
            val_sequences = {k: v[n_train:] for k, v in full_sequences.items()}
            y_train = y_tensor[:n_train]
            y_val = y_tensor[n_train:]

            print(f"‚úÖ Split: Train {len(y_train)}, Val {len(y_val)}")

            # Configuration d'entra√Ænement simple
            from torch.optim import AdamW
            from torch.nn import CrossEntropyLoss

            optimizer = AdamW(model.parameters(), lr=1e-4, weight_decay=0.01)
            criterion = CrossEntropyLoss()

            device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
            model.to(device)
            print(f"Device: {device}")

            # Entra√Ænement rapide
            print("\nüî• Entra√Ænement (3 √©poques)...")

            num_epochs = 3
            batch_size_train = 8

            for epoch in range(num_epochs):
                model.train()
                total_loss = 0
                n_batches = 0

                for i in range(0, len(y_train), batch_size_train):
                    end_idx = min(i + batch_size_train, len(y_train))

                    batch_data = {
                        k: v[i:end_idx].to(device) for k, v in train_sequences.items()
                    }
                    batch_targets = y_train[i:end_idx].to(device)

                    optimizer.zero_grad()

                    try:
                        outputs = model(batch_data)
                        loss = criterion(outputs, batch_targets)
                        loss.backward()

                        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                        optimizer.step()

                        total_loss += loss.item()
                        n_batches += 1

                    except Exception as batch_error:
                        print(f"‚ö†Ô∏è Erreur batch: {batch_error}")
                        continue

                avg_loss = total_loss / max(n_batches, 1)
                print(f"√âpoque {epoch + 1}: Loss = {avg_loss:.4f}")

            # √âvaluation
            print("\nüìä √âvaluation...")
            model.eval()
            correct = 0
            total_eval = 0

            with torch.no_grad():
                for i in range(0, len(y_val), batch_size_train):
                    end_idx = min(i + batch_size_train, len(y_val))

                    batch_data = {
                        k: v[i:end_idx].to(device) for k, v in val_sequences.items()
                    }
                    batch_targets = y_val[i:end_idx].to(device)

                    try:
                        outputs = model(batch_data)
                        predictions = torch.argmax(outputs, dim=1)
                        correct += (predictions == batch_targets).sum().item()
                        total_eval += batch_targets.size(0)
                    except:
                        continue

            accuracy = correct / max(total_eval, 1)
            print(f"‚úÖ Pr√©cision: {accuracy:.2%}")

            # Sauvegarde
            save_dict = {
                "model_state_dict": model.state_dict(),
                "config": CONFIG,
                "schema": schema,
                "label_encoder": label_encoder,
                "accuracy": accuracy,
                "transformers4rec_version": "23.04.00",
            }

            torch.save(save_dict, "t4rec_xlnet_working_model.pth")
            print("‚úÖ Mod√®le sauvegard√©: t4rec_xlnet_working_model.pth")
            print("üéâ SUCC√àS COMPLET!")

        else:
            print(f"‚ùå Colonne target '{target_col}' non trouv√©e")

    else:
        print("‚ùå √âchec du test - arr√™t")

except Exception as e:
    print(f"‚ùå ERREUR: {e}")
    import traceback

    traceback.print_exc()

    # Debug info
    print(f"\nüîç DEBUG:")
    print(
        f"Variables disponibles: {[name for name in globals().keys() if not name.startswith('_')]}"
    )
    if "tabular_data" in globals():
        print(f"tabular_data keys: {list(tabular_data.keys())[:5]}")
    if "df" in globals():
        print(f"df shape: {df.shape if hasattr(df, 'shape') else 'N/A'}")

