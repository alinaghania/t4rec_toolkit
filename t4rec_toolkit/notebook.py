# === ENTRAÃNEMENT DU MODÃˆLE T4REC - VERSION XLNET CORRIGÃ‰E ===

print("ğŸš€ ENTRAÃNEMENT DU MODÃˆLE XLNET CORRIGÃ‰")
print("=" * 55)

# Imports
from t4rec_toolkit.models import ModelRegistry, XLNetModelBuilder, create_model
from t4rec_toolkit.models.registry import get_available_models
import torch
import transformers4rec.torch as tr

try:
    # 1. VÃ©rifier les modÃ¨les disponibles
    available_models = get_available_models()
    print(f"ğŸ“‹ ModÃ¨les disponibles: {available_models}")

    # 2. CrÃ©er un schÃ©ma T4Rec natif AVEC ITEM_ID
    print("ğŸ—ï¸ CrÃ©ation du schÃ©ma T4Rec avec item_id...")
    
    # Utiliser l'API merlin.schema
    from merlin.schema import Schema, ColumnSchema, Tags
    
    # CrÃ©er les colonnes du schÃ©ma
    columns = []
    
    # IMPORTANT: Ajouter un item_id requis pour T4Rec masking
    print("   â­ Ajout de l'item_id requis pour T4Rec masking")
    item_id_column = ColumnSchema(
        name="item_id",
        tags={Tags.CATEGORICAL, Tags.ITEM, Tags.ID},
        dtype="int32",
        is_list=False,
        properties={"vocab_size": 10000}  # Vocabulaire suffisant
    )
    columns.append(item_id_column)
    print(f"   âœ… Item ID: item_id (vocab_size=10000)")
    
    # Ajouter les features sÃ©quentielles (continues)
    sequence_features = [
        'nbchqemigliss_m12_sequence',
        'nb_automobile_12dm_sequence', 
        'mntecscrdimm_sequence',
        'mnt_euro_r_3m_sequence',
        'nb_contacts_accueil_service_sequence'
    ]
    
    for feature_name in sequence_features:
        column = ColumnSchema(
            name=feature_name,
            tags={Tags.CONTINUOUS, Tags.LIST},
            dtype="float32",
            is_list=True,
            properties={"max_sequence_length": 20}
        )
        columns.append(column)
        print(f"   âœ… SÃ©quence continue: {feature_name}")

    # Ajouter les features catÃ©gorielles
    categorical_features = [
        'dummy:iac_epa:03_encoded',
        'dummy:iac_epa:01_encoded', 
        'dummy:iac_epa:02_encoded',
        'dummy:iac_epa:N/A_encoded',
        'dummy:iac_epa:__Others___encoded'
    ]
    
    for feature_name in categorical_features:
        column = ColumnSchema(
            name=feature_name,
            tags={Tags.CATEGORICAL},
            dtype="int32",
            is_list=False,
            properties={"vocab_size": 20}
        )
        columns.append(column)
        print(f"   âœ… CatÃ©gorielle: {feature_name}")

    # CrÃ©er le schÃ©ma avec toutes les colonnes (item_id + features)
    schema = Schema(columns)
    total_features = len(sequence_features) + len(categorical_features) + 1  # +1 pour item_id
    print(f"âœ… SchÃ©ma crÃ©Ã© avec {total_features} features (incluant item_id)")
    
    # 3. Convertir le schÃ©ma pour le registry avec item_id
    schema_dict = {
        "feature_specs": [],
        "sequence_length": 20,
        "has_item_id": True  # Marquer que nous avons un item_id
    }
    
    for column in columns:
        spec = {
            "name": column.name,
            "dtype": str(column.dtype),
            "is_sequence": column.is_list,
            "is_continuous": Tags.CONTINUOUS in column.tags,
            "is_categorical": Tags.CATEGORICAL in column.tags,
            "is_item_id": Tags.ITEM in column.tags and Tags.ID in column.tags,
        }
        
        if column.properties:
            spec.update(column.properties)
            
        schema_dict["feature_specs"].append(spec)
    
    print(f"ğŸ”§ SchÃ©ma converti avec item_id: {len(schema_dict['feature_specs'])} specs")
    
    # 4. PrÃ©parer les donnÃ©es AVEC item_id artificiel
    print("\nğŸ“Š PRÃ‰PARATION DES DONNÃ‰ES AVEC ITEM_ID")
    print("-" * 40)
    
    # CrÃ©er un item_id artificiel basÃ© sur l'index ou les features
    import numpy as np
    import pandas as pd
    from sklearn.preprocessing import LabelEncoder
    
    # MÃ©thode 1: CrÃ©er des item_id basÃ©s sur les combinaisons de features catÃ©gorielles
    def create_item_ids(data_dict, categorical_feature_names):
        """CrÃ©e des item_id artificiels basÃ©s sur les features catÃ©gorielles."""
        
        # ConcatÃ©ner toutes les features catÃ©gorielles pour crÃ©er des "items" uniques
        item_signatures = []
        
        # Obtenir la longueur des donnÃ©es
        sample_key = next(iter(data_dict.keys()))
        n_samples = len(data_dict[sample_key])
        
        for i in range(n_samples):
            # CrÃ©er une signature basÃ©e sur les features catÃ©gorielles
            signature_parts = []
            for feat_name in categorical_feature_names:
                if feat_name in data_dict:
                    # Prendre la valeur ou la moyenne si c'est un array
                    val = data_dict[feat_name][i]
                    if isinstance(val, np.ndarray):
                        val = int(val.mean()) if len(val) > 0 else 0
                    signature_parts.append(str(int(val)))
                else:
                    signature_parts.append("0")
            
            item_signatures.append("_".join(signature_parts))
        
        # Encoder les signatures en item_id numÃ©riques
        le = LabelEncoder()
        item_ids = le.fit_transform(item_signatures)
        
        print(f"   âœ… {len(np.unique(item_ids))} item_id uniques crÃ©Ã©s")
        return item_ids, le
    
    # Extraire les noms des features catÃ©gorielles
    categorical_names = [name for name in categorical_features if name in tabular_data]
    
    if categorical_names:
        item_ids, item_encoder = create_item_ids(tabular_data, categorical_names)
    else:
        # Fallback: utiliser des item_id sÃ©quentiels
        item_ids = np.arange(len(next(iter(tabular_data.values()))))
        item_encoder = None
        print("   âœ… Item_id sÃ©quentiels crÃ©Ã©s (fallback)")
    
    # Ajouter item_id aux donnÃ©es
    tabular_data_with_itemid = tabular_data.copy()
    tabular_data_with_itemid['item_id'] = item_ids
    
    print(f"   ğŸ“ˆ DonnÃ©es prÃ©parÃ©es avec item_id: {len(tabular_data_with_itemid)} features")
    
    # 5. Test de crÃ©ation du modÃ¨le XLNet avec item_id
    print("\nğŸ§ª TEST DU MODÃˆLE XLNET AVEC ITEM_ID")
    print("-" * 40)
    
    # Configuration XLNet sans masking pour Ã©viter les problÃ¨mes
    xlnet_config_safe = {
        'd_model': 256,
        'n_head': 8,
        'n_layer': 4,
        'max_sequence_length': 20,
        'mem_len': 50,
        'dropout': 0.1,
        'masking': None,  # DÃ©sactiver le masking temporairement
        'attn_type': 'bi'
    }
    
    print("Configuration XLNet (masking dÃ©sactivÃ© pour test):")
    for key, value in xlnet_config_safe.items():
        print(f"   {key}: {value}")
    
    try:
        # Test de crÃ©ation du modÃ¨le
        model = create_model(
            architecture="xlnet",
            schema=schema_dict,
            **xlnet_config_safe
        )
        
        print("âœ… ModÃ¨le XLNet crÃ©Ã© avec succÃ¨s (sans masking)")
        print(f"ğŸ“ˆ ParamÃ¨tres du modÃ¨le: {sum(p.numel() for p in model.parameters()):,}")
        
        model_created = True
        
    except Exception as e:
        print(f"âŒ Ã‰chec crÃ©ation modÃ¨le XLNet: {e}")
        model_created = False
    
    # 6. Si le modÃ¨le est crÃ©Ã©, procÃ©der Ã  l'entraÃ®nement
    if model_created:
        print("\nğŸ¯ ENTRAÃNEMENT DU MODÃˆLE XLNET")
        print("-" * 35)
        
        from sklearn.model_selection import train_test_split
        
        def prepare_torch_data_with_itemid(data_dict):
            """Convertit les donnÃ©es avec item_id en format torch."""
            torch_data = {}
            for feature_name, feature_data in data_dict.items():
                if isinstance(feature_data, np.ndarray):
                    if 'sequence' in feature_name:
                        torch_data[feature_name] = torch.tensor(feature_data, dtype=torch.float32)
                    else:
                        torch_data[feature_name] = torch.tensor(feature_data, dtype=torch.int32)
                else:
                    torch_data[feature_name] = torch.tensor(feature_data, dtype=torch.int32)
            return torch_data

        # PrÃ©parer les donnÃ©es avec item_id
        X_torch = prepare_torch_data_with_itemid(tabular_data_with_itemid)
        y = df['souscription_produit_1m'].values

        # Encoder le target
        label_encoder = LabelEncoder()
        y_encoded = label_encoder.fit_transform(y)
        y_torch = torch.tensor(y_encoded, dtype=torch.long)

        print(f"Features avec item_id: {len(X_torch)}")
        print(f"Target classes: {len(label_encoder.classes_)}")

        # Split train/validation
        indices = np.arange(len(y_torch))
        train_indices, val_indices = train_test_split(
            indices, test_size=0.2, random_state=42, stratify=y_encoded
        )

        X_train = {k: v[train_indices] for k, v in X_torch.items()}
        X_val = {k: v[val_indices] for k, v in X_torch.items()}
        y_train = y_torch[train_indices]
        y_val = y_torch[val_indices]

        print(f"Train: {len(train_indices)} Ã©chantillons")
        print(f"Validation: {len(val_indices)} Ã©chantillons")

        # Configuration de l'entraÃ®nement
        from torch.optim import AdamW
        from torch.nn import CrossEntropyLoss

        optimizer = AdamW(model.parameters(), lr=3e-5, weight_decay=0.01)
        criterion = CrossEntropyLoss()
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        model.to(device)

        print(f"Device: {device}")

        # EntraÃ®nement
        num_epochs = 12
        batch_size = 16  # Batch size plus petit pour XLNet

        train_losses = []
        val_losses = []

        print(f"\nDÃ©but entraÃ®nement: {num_epochs} Ã©poques, batch_size={batch_size}")

        for epoch in range(num_epochs):
            # Mode entraÃ®nement
            model.train()
            total_train_loss = 0
            num_batches = 0

            for i in range(0, len(train_indices), batch_size):
                batch_indices = train_indices[i:i+batch_size]
                
                batch_X = {k: v[batch_indices].to(device) for k, v in X_train.items()}
                batch_y = y_train[i:i+batch_size].to(device)

                optimizer.zero_grad()
                
                try:
                    outputs = model(batch_X)
                    loss = criterion(outputs, batch_y)
                    loss.backward()
                    
                    # Gradient clipping pour XLNet
                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                    
                    optimizer.step()
                    total_train_loss += loss.item()
                    num_batches += 1
                    
                except Exception as batch_error:
                    print(f"Erreur batch {i}: {batch_error}")
                    continue

            # Mode Ã©valuation
            model.eval()
            total_val_loss = 0
            num_val_batches = 0

            with torch.no_grad():
                for i in range(0, len(val_indices), batch_size):
                    batch_indices = val_indices[i:i+batch_size]
                    
                    batch_X = {k: v[batch_indices].to(device) for k, v in X_val.items()}
                    batch_y = y_val[i:i+batch_size].to(device)

                    try:
                        outputs = model(batch_X)
                        loss = criterion(outputs, batch_y)
                        total_val_loss += loss.item()
                        num_val_batches += 1
                    except Exception as val_error:
                        continue

            if num_batches > 0 and num_val_batches > 0:
                avg_train_loss = total_train_loss / num_batches
                avg_val_loss = total_val_loss / num_val_batches
                
                train_losses.append(avg_train_loss)
                val_losses.append(avg_val_loss)
                
                if (epoch + 1) % 3 == 0 or epoch == 0:
                    print(f"Ã‰poque {epoch+1}: Train={avg_train_loss:.4f}, Val={avg_val_loss:.4f}")

        print("âœ… EntraÃ®nement terminÃ©!")

        # Ã‰valuation finale
        model.eval()
        correct = 0
        total = 0
        
        with torch.no_grad():
            for i in range(0, len(val_indices), batch_size):
                batch_indices = val_indices[i:i+batch_size]
                batch_X = {k: v[batch_indices].to(device) for k, v in X_val.items()}
                batch_y = y_val[i:i+batch_size].to(device)
                
                try:
                    outputs = model(batch_X)
                    predictions = torch.argmax(outputs, dim=1)
                    correct += (predictions == batch_y).sum().item()
                    total += batch_y.size(0)
                except:
                    continue
        
        if total > 0:
            accuracy = correct / total
            print(f"Accuracy finale: {accuracy:.2%}")
        else:
            accuracy = 0.0
            print("Impossible de calculer l'accuracy")

        # Sauvegarder le modÃ¨le
        torch.save({
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'schema': schema_dict,
            'tabular_data_with_itemid': list(tabular_data_with_itemid.keys()),
            'label_encoder': label_encoder,
            'item_encoder': item_encoder,
            'xlnet_config': xlnet_config_safe,
            'train_losses': train_losses,
            'val_losses': val_losses,
            'final_accuracy': accuracy,
            'model_type': 'xlnet_with_itemid'
        }, 't4rec_xlnet_with_itemid.pth')

        print("ğŸ’¾ ModÃ¨le sauvegardÃ©: t4rec_xlnet_with_itemid.pth")
        
    else:
        # Fallback: modÃ¨le PyTorch simple
        print("\nğŸ”„ FALLBACK: MODÃˆLE PYTORCH SIMPLE")
        print("-" * 40)
        
        class SimpleClassifier(torch.nn.Module):
            def __init__(self, input_dim, n_classes):
                super().__init__()
                self.fc1 = torch.nn.Linear(input_dim, 256)
                self.fc2 = torch.nn.Linear(256, 128)
                self.fc3 = torch.nn.Linear(128, n_classes)
                self.dropout = torch.nn.Dropout(0.3)
                self.relu = torch.nn.ReLU()
                
            def forward(self, x):
                if isinstance(x, dict):
                    # ConcatÃ©ner toutes les features
                    features = []
                    for value in x.values():
                        if value.dim() > 2:
                            value = value.mean(dim=1)
                        if value.dim() == 1:
                            value = value.unsqueeze(1)
                        features.append(value.float())
                    x = torch.cat(features, dim=1)
                
                x = self.relu(self.fc1(x))
                x = self.dropout(x)
                x = self.relu(self.fc2(x))
                x = self.dropout(x)
                return self.fc3(x)
        
        # Calculer la dimension d'entrÃ©e
        sample_input = prepare_torch_data_with_itemid(tabular_data_with_itemid)
        total_dim = 0
        for key, value in sample_input.items():
            if value.dim() > 1:
                total_dim += value.shape[1] if value.dim() == 2 else 1
            else:
                total_dim += 1
        
        simple_model = SimpleClassifier(total_dim, len(np.unique(y)))
        print(f"âœ… ModÃ¨le PyTorch simple crÃ©Ã©: {total_dim} -> {len(np.unique(y))} classes")
        print(f"ğŸ“ˆ ParamÃ¨tres: {sum(p.numel() for p in simple_model.parameters()):,}")

except Exception as e:
    print(f"\nâŒ ERREUR GÃ‰NÃ‰RALE: {e}")
    import traceback
    traceback.print_exc()
    
    print("\nğŸ’¡ SOLUTIONS RECOMMANDÃ‰ES:")
    print("1. L'item_id est maintenant inclus dans le schÃ©ma")
    print("2. Le masking est dÃ©sactivÃ© pour Ã©viter les erreurs")
    print("3. Un modÃ¨le PyTorch simple est disponible en fallback")
    print("4. VÃ©rifiez que vos donnÃ©es 'tabular_data' et 'df' sont bien dÃ©finies")
